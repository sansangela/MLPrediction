{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Params\n",
    "input_seq_length = 8\n",
    "output_seq_length = 12\n",
    "seq_length = input_seq_length + output_seq_length\n",
    "num_features = 2\n",
    "hidden_dim = 128\n",
    "embedding_dim = 64\n",
    "grad_clip = 10.0\n",
    "\n",
    "# Discretization\n",
    "neighborhood_size = 32\n",
    "# grid_ratio = 0.001\n",
    "grid_size = 0.5\n",
    "# spatial_pooling_size = 32\n",
    "# pooling_window_size = (8, 8)\n",
    "\n",
    "# Training Params\n",
    "num_epochs = 5\n",
    "batch_size = 5\n",
    "learning_rate = 0.005\n",
    "decay_rate = 0.95\n",
    "dropout_keep_prob = 0.8\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load preprocessed data\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataLoader\n",
    "\n",
    "file_path = \"../..//data/eth/hotel/pixel_pos_interpolatae.csv\"\n",
    "dataset_name = \"eth_hotel\"\n",
    "file_path_processed = \"../..//data/preprocessed/\"\n",
    "\n",
    "dataloader = DataLoader(file_path, dataset_name, file_path_processed, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n",
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, ReLU, LSTMCell, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import time\n",
    "\n",
    "# Check TensorFlow version\n",
    "tf_version = tf.__version__\n",
    "print(\"TensorFlow version:\", tf_version)\n",
    "\n",
    "# Check if there is a GPU available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_occupancy_map(dense_representation, ped_id_to_index_map, num_peds_per_seq, ped_per_frame, is_animate=False):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dense_representation (numpy.ndarray): _description_\n",
    "        ped_id_to_index_map (dict): _description_\n",
    "        num_peds_per_seq (_type_): _description_\n",
    "        ped_per_frame (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        occupancy_grid (lsit(tf.Variable)): occupancy_grid[i] with shape (num_peds_per_seq, num_peds_per_seq, neighborhood_size**2)\n",
    "    \"\"\"\n",
    "    grid_size_half = grid_size / 2.0\n",
    "\n",
    "    if is_animate:\n",
    "        plot_animation(dense_representation, ped_id_to_index_map, [1,3])\n",
    "\n",
    "    occupancy_grid = []\n",
    "\n",
    "    for frame_id in range(seq_length):\n",
    "        occupancy_grid_frame = np.zeros((num_peds_per_seq, num_peds_per_seq, neighborhood_size, neighborhood_size))\n",
    "        \n",
    "        ped_indices = [ped_id_to_index_map[ped_id] for ped_id in ped_per_frame[frame_id]]\n",
    "\n",
    "        for ped_i, ped_j in itertools.permutations(ped_indices, 2):\n",
    "            ped_i_y, ped_i_x = dense_representation[frame_id, ped_i]\n",
    "            ped_j_y, ped_j_x = dense_representation[frame_id, ped_j]\n",
    "            ped_i_neighbor_y_low, ped_i_neighbor_x_low = ped_i_y - grid_size_half, ped_i_x - grid_size_half\n",
    "            ped_i_neighbor_y_high, ped_i_neighbor_x_high = ped_i_y + grid_size_half - 1, ped_i_x + grid_size_half - 1\n",
    "\n",
    "            if ped_j_y >= ped_i_neighbor_y_low and ped_j_y <= ped_i_neighbor_y_high and ped_j_x >= ped_i_neighbor_x_low and ped_j_x <= ped_i_neighbor_x_high:\n",
    "                # ped_j in ped_i neighborhood\n",
    "                cell_y = int(np.floor((ped_j_y - ped_i_neighbor_y_low) / grid_size * neighborhood_size))\n",
    "                cell_x = int(np.floor((ped_j_x - ped_i_neighbor_x_low) / grid_size * neighborhood_size))\n",
    "                occupancy_grid_frame[ped_i, ped_j, cell_y, cell_x] = 1\n",
    "\n",
    "        occupancy_grid.append(tf.Variable(tf.reshape(occupancy_grid_frame, (num_peds_per_seq, num_peds_per_seq, -1))))\n",
    "\n",
    "    return occupancy_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocialLSTM(Model):\n",
    "    def __init__(self, embedding_dim=64, hidden_dim=128, pool_size=(8,8), neighbors=32, num_features=2, out_features=5, dropout=0.5):\n",
    "        super(SocialLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_embedding_layer = Dense(embedding_dim)\n",
    "        self.social_embedding_layer = Dense(embedding_dim)  # TODO\n",
    "        self.lstm = LSTMCell(hidden_dim)\n",
    "        self.output_embedding_layer = Dense(out_features)\n",
    "        self.dropout_layer = Dropout(dropout)\n",
    "\n",
    "        self.relu = ReLU()\n",
    "\n",
    "\n",
    "    def call(self, input, lstm_hidden, lstm_cell, occupancy_grid):\n",
    "        # occupancy_grid: (seq_length, num_peds_per_seq, num_peds_per_seq, neighborhood_size*neighborhood_size)\n",
    "        out_split = tf.split(tf.zeros(input.shape), num_or_size_splits=input.shape[0], axis=0)\n",
    "                    \n",
    "        for frame_id in range(input.shape[0]):\n",
    "            # Input embedding\n",
    "            input_t = input[frame_id]\n",
    "            input_embed_out = self.input_embedding_layer(input_t)\n",
    "            input_embed_out = self.relu(input_embed_out)\n",
    "            # input_embed_out = self.dropout_layer(input_embed_out)\n",
    "\n",
    "            # Social embedding\n",
    "            occupancy_grid_frame = occupancy_grid[frame_id]\n",
    "            occupancy_grid_frame_float32 = tf.cast(occupancy_grid_frame, dtype=tf.float32)  # cast from float64 to float32\n",
    "\n",
    "            result = tf.einsum('ijk,jx->ikx', occupancy_grid_frame_float32, lstm_hidden)    # (num_peds_per_seq, num_peds_per_seq, neighborhood_size**2), (num_peds_per_seq, hidden_dim) -> (num_peds_per_seq, neighborhood_size**2, hidden_dim)\n",
    "            result = tf.reshape(result, (result.shape[0], -1))\n",
    "\n",
    "            social_embed_out = self.social_embedding_layer(result)\n",
    "            social_embed_out = self.relu(social_embed_out)\n",
    "            # social_embed_out = self.dropout_layer(social_embed_out)\n",
    "\n",
    "            # Concat input embedding and social embedding outputs\n",
    "            embed_out = tf.concat([input_embed_out, social_embed_out], axis=1)\n",
    "\n",
    "            # LSTM\n",
    "            lstm_out, new_state = self.lstm(embed_out, (lstm_hidden, lstm_cell))\n",
    "            lstm_hidden, lstm_cell = new_state\n",
    "            \n",
    "            # Output embedding\n",
    "            out_t = self.output_embedding_layer(lstm_out)\n",
    "\n",
    "            out_t = tf.expand_dims(out_t, axis=0)\n",
    "\n",
    "            out_split[frame_id] = out_t\n",
    "        \n",
    "        out = tf.concat(out_split, axis=0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred, ped_id_to_index_map):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error (MSE) loss between predicted and true positions.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): True pedestrian positions of shape (num_sequences, np.array(num_pedestrians, 3)).\n",
    "        y_pred (tf.Tensor): Predicted pedestrian positions of shape (num_sequences, num_pedestrians, 2).\n",
    "        ped_id_to_index_map (dict): Dictionary mapping pedestrian IDs to their indices.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Mean Squared Error loss.\n",
    "    \"\"\"\n",
    "    num_seq, num_ped = len(y_true), len(ped_id_to_index_map)\n",
    "    y_true_dense_representation = np.zeros((num_seq, num_ped, 2))\n",
    "    for sequence_idx in range(len(y_true)):\n",
    "        indices = [ped_id_to_index_map[x] for x in y_true[sequence_idx][:, 0] if x in ped_id_to_index_map.keys()]\n",
    "        if not indices:\n",
    "            continue\n",
    "        y_true_dense_representation[sequence_idx, indices, :] = y_true[sequence_idx][:, 1:3]\n",
    "    \n",
    "    return -tf.math.reduce_mean(y_true_dense_representation-y_pred)\n",
    "\n",
    "def gaussian_loss(y_true, y_out, ped_id_to_index_map, input_seq_length = 8, output_seq_length = 12):\n",
    "    # y_out: shape (seq_length, num_ped, 5)\n",
    "    num_seq, num_ped = len(y_true), len(ped_id_to_index_map)\n",
    "    y_true_dense_representation = np.zeros((num_seq, num_ped, 2))\n",
    "    for sequence_idx in range(len(y_true)):\n",
    "        indices = [ped_id_to_index_map[x] for x in y_true[sequence_idx][:, 0] if x in ped_id_to_index_map.keys()]\n",
    "        if not indices:\n",
    "            continue\n",
    "        y_true_dense_representation[sequence_idx, indices, :] = y_true[sequence_idx][:, 1:3]\n",
    "    \n",
    "    mu_y, mu_x, sigma_y, sigma_x, rho = y_out[:,:,0], y_out[:,:,1], y_out[:,:,2], y_out[:,:,3], y_out[:,:,4]\n",
    "    \n",
    "    y_offset = y_true_dense_representation[:,:,0] - mu_y\n",
    "    x_offset = y_true_dense_representation[:,:,1] - mu_x\n",
    "\n",
    "    z = (x_offset/sigma_x)**2 + (y_offset/sigma_y)**2 - 2.0*rho*x_offset*y_offset/(sigma_x*sigma_y)\n",
    "    constant = - 1.0 / (2.0 * (1 - rho**2))\n",
    "\n",
    "    epsilon = 1e-20\n",
    "    result = tf.math.exp(constant*z) / (2*tf.constant(np.pi)*sigma_x*sigma_y*tf.math.sqrt(1-rho**2))\n",
    "    result = -tf.math.log(tf.clip_by_value(result, clip_value_min=epsilon, clip_value_max=tf.float32.max))\n",
    "\n",
    "    # Sum over all pedestrians\n",
    "    # result = constant * z - 0.5 * tf.math.log(2 * tf.constant(np.pi) * sigma_x**2 * sigma_y**2)\n",
    "    # result = tf.reduce_sum(result, axis=1) / num_ped\n",
    "\n",
    "    loss = tf.reduce_sum(result[input_seq_length:input_seq_length+output_seq_length]) / output_seq_length\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one step loses:  tf.Tensor(391.14987, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(102.831406, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(23.649584, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(96.41806, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(1.3696456, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(615.4186, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(176.33502, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(199.60292, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(10.414954, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(13.583582, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(291.2459, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(691.1824, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-1.6579301, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(95.40254, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(205.03874, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(45.029385, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(11.189482, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(355.00223, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(5.765747, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(8.162997, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(30.989218, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(2.6660671, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(2.0274515, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(49.61148, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(1.6205894, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(3.4028265, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.1852002, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(18.133018, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.810199, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(14.161035, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(21.62638, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.2291245, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.711254, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(0.6582105, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-4.8282037, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(4.51601, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(181.17601, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(215.99318, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(181.55574, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(230.53944, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(276.77267, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(1086.037, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(0.00610739, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(2.7965057, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-0.8822335, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(170.12051, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(50.40268, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(222.44357, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.13836, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(6.3320684, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-0.5230486, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(138.37723, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(228.46861, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(366.51648, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(47.375015, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-3.6544106, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(1.4993333, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-5.205378, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.484946, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(33.52961, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(100.00724, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-3.4351819, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-5.066155, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-8.174273, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(88.5064, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(171.83804, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(96.63127, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(41.492195, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-0.82133275, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(25.689562, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-0.19099039, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(162.8007, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(9.485818, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(3.307838, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(4.8763027, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.8583543, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(21.28551, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(36.097115, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.3301613, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-0.77298987, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-3.90024, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(43.029594, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(46.31749, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(82.34369, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(99.00529, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(42.517155, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-3.3682432, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.8759367, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(13.256488, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(148.53476, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-0.8558863, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(1.4176439, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.2569253, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.5805955, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.049345, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(-10.325109, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-7.7044277, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.3623323, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.715469, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-13.075034, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(191.22641, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(157.36914, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-6.5985646, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-10.988594, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-7.324328, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-9.221535, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(41.39799, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(7.2649727, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(-2.5673265, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(46.235947, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "one step loses:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "total batch loss:  tf.Tensor(nan, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c18a71ef1d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one step loses: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total batch loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_unaggregated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m       return tf.__internal__.distribute.interim.maybe_merge_call(\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_transform_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;34m\"\"\"Called in `apply_gradients` after aggregation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clipvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clipvalue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clipnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clipnorm_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mgradient_clipvalue_fn\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m    142\u001b[0m     clipped_grads_and_vars = [(tf.clip_by_value(g, -clipvalue,\n\u001b[1;32m    143\u001b[0m                                                       clipvalue), v)\n\u001b[0;32m--> 144\u001b[0;31m                               for g, v in grads_and_vars]\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclipped_grads_and_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m     clipped_grads_and_vars = [(tf.clip_by_value(g, -clipvalue,\n\u001b[1;32m    143\u001b[0m                                                       clipvalue), v)\n\u001b[0;32m--> 144\u001b[0;31m                               for g, v in grads_and_vars]\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclipped_grads_and_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py\u001b[0m in \u001b[0;36mclip_by_value\u001b[0;34m(t, clip_value_min, clip_value_max, name)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_min\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mt_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_value_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Software/anaconda/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmaximum\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6179\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 6180\u001b[0;31m         _ctx, \"Maximum\", name, x, y)\n\u001b[0m\u001b[1;32m   6181\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6182\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import mse_loss\n",
    "import time\n",
    "\n",
    "device = '/CPU:0'\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device = '/GPU:0'\n",
    "    print(\"Using GPU...\")\n",
    "\n",
    "dataloader.reset_frame_ptr()\n",
    "with tf.device(device):\n",
    "\n",
    "    # Declare model and optimizer\n",
    "    model = SocialLSTM()\n",
    "    lr = tf.Variable(learning_rate, trainable=False)\n",
    "    optimizer = RMSprop(lr, clipvalue=grad_clip)\n",
    "\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0      \n",
    "\n",
    "        # For each batch  \n",
    "        for batch in dataloader.generate_batches():\n",
    "            start_time = time.time()\n",
    "            inputs, targets, batch_ped_indices = batch\n",
    "            if not inputs or not targets:\n",
    "                # Traverse to the end\n",
    "                break\n",
    "\n",
    "            # ped_per_frame = dataloader.ped_indices\n",
    "            batch_loss = 0.0\n",
    "\n",
    "            # For each sequence\n",
    "            for sequence_idx in range(batch_size):\n",
    "                input, target, ped_per_frame = inputs[sequence_idx], targets[sequence_idx], batch_ped_indices[sequence_idx]\n",
    "\n",
    "                dense_representation, ped_id_to_index_map = dataloader.convert_to_dense_representation(input) \n",
    "                dense_representation_tf = tf.Variable(tf.convert_to_tensor(dense_representation))\n",
    "                num_peds_per_frame = len(ped_id_to_index_map)\n",
    "\n",
    "                # Create occupancy grid\n",
    "                occupancy_grid = get_occupancy_map(dense_representation, ped_id_to_index_map, num_peds_per_frame, ped_per_frame)\n",
    "                \n",
    "                # Initialize LSTM params\n",
    "                lstm_hidden = tf.Variable(tf.random.truncated_normal((num_peds_per_frame, hidden_dim), stddev=0.1))\n",
    "                lstm_cell = tf.Variable(tf.random.truncated_normal((num_peds_per_frame, hidden_dim), stddev=0.1))\n",
    "\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Forward pass\n",
    "                    out = model(dense_representation_tf, lstm_hidden, lstm_cell, occupancy_grid)\n",
    "                    loss = gaussian_loss(target, out, ped_id_to_index_map)\n",
    "                    loss += 0.0005 * sum(tf.reduce_sum(tf.square(vars)) for vars in model.trainable_variables)    \n",
    "                batch_loss += loss\n",
    "\n",
    "\n",
    "                # Compute gradients\n",
    "                grads = tape.gradient(loss, model.trainable_variables)\n",
    "                # print(grads)\n",
    "\n",
    "                # Clip gradients by norm\n",
    "                grads, _ = tf.clip_by_global_norm(grads, grad_clip)\n",
    "\n",
    "                \n",
    "                # Update parameters\n",
    "                trainable_variables = model.trainable_variables\n",
    "                optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "                print(\"one step loses: \", loss)\n",
    "            print(\"total batch loss: \", batch_loss)\n",
    "            batch_loss /= batch_size\n",
    "        epoch_loss += batch_loss\n",
    "        batch_time = time.time() - start_time\n",
    "        print(\"Batch time: \", batch_time)\n",
    "            \n",
    "    print('(epoch {}/{}), train_loss = {:.3f}'.format(\n",
    "                epoch,\n",
    "                num_epochs,\n",
    "                epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_loss tf.Tensor(278.7958, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(15.299756, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(15.72596, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(117.12273, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(120.94258, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(6.3819237, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(60.49824, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(1.8956293, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(210.36592, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(14.9192295, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(1.4831622, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(20.914919, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(1.7142359, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(0.045264922, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-0.43390432, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(46.42433, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(46.11577, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(32.57626, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-0.10405548, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-2.0573053, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(5.492521, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(3.4816117, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(0.9693022, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-0.20723999, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-2.484303, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(11.520863, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-1.745355, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(0.2227633, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-7.0555367, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(-18.681168, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(229.6622, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(91.44795, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(21.119942, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "batch_loss tf.Tensor(nan, shape=(), dtype=float32)\n",
      "(epoch 0/5), train_loss = nan\n",
      "(epoch 1/5), train_loss = nan\n",
      "(epoch 2/5), train_loss = nan\n",
      "(epoch 3/5), train_loss = nan\n",
      "(epoch 4/5), train_loss = nan\n"
     ]
    }
   ],
   "source": [
    "from utils import mse_loss\n",
    "\n",
    "device = '/CPU:0'\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device = '/GPU:0'\n",
    "    print(\"Using GPU...\")\n",
    "\n",
    "dataloader.reset_frame_ptr()\n",
    "with tf.device(device):\n",
    "\n",
    "    # Declare model and optimizer\n",
    "    model = SocialLSTM()\n",
    "    lr = tf.Variable(learning_rate, trainable=False)\n",
    "    optimizer = RMSprop(lr, clipvalue=grad_clip)\n",
    "\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0      \n",
    "\n",
    "        # For each batch  \n",
    "        for batch in dataloader.generate_batches():\n",
    "            inputs, targets, batch_ped_indices = batch\n",
    "            if not inputs or not targets:\n",
    "                # Traverse to the end\n",
    "                break\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "                # ped_per_frame = dataloader.ped_indices\n",
    "                batch_loss = 0.0\n",
    "\n",
    "                # For each sequence\n",
    "                for sequence_idx in range(batch_size):\n",
    "                    input, target, ped_per_frame = inputs[sequence_idx], targets[sequence_idx], batch_ped_indices[sequence_idx]\n",
    "\n",
    "                    dense_representation, ped_id_to_index_map = dataloader.convert_to_dense_representation(input) \n",
    "                    dense_representation_tf = tf.constant(tf.convert_to_tensor(dense_representation))\n",
    "                    num_peds_per_frame = len(ped_id_to_index_map)\n",
    "\n",
    "                    # Create occupancy grid\n",
    "                    occupancy_grid = get_occupancy_map(dense_representation, ped_id_to_index_map, num_peds_per_frame, ped_per_frame)\n",
    "                    \n",
    "                    # Initialize LSTM params\n",
    "                    lstm_hidden = tf.Variable(tf.random.truncated_normal((num_peds_per_frame, hidden_dim), stddev=0.1))\n",
    "                    lstm_cell = tf.Variable(tf.random.truncated_normal((num_peds_per_frame, hidden_dim), stddev=0.1))\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    out = model(dense_representation_tf, lstm_hidden, lstm_cell, occupancy_grid)\n",
    "                    loss = gaussian_loss(target, out, ped_id_to_index_map)\n",
    "                    batch_loss += loss\n",
    "                \n",
    "            \n",
    "                batch_loss += 0.0005 * sum(tf.reduce_sum(tf.square(vars)) for vars in model.trainable_variables)    \n",
    "                \n",
    "            # Compute gradients\n",
    "            grads = tape.gradient(batch_loss, model.trainable_variables)\n",
    "            # print(grads)\n",
    "\n",
    "            # Clip gradients by norm\n",
    "            grads, _ = tf.clip_by_global_norm(grads, grad_clip)\n",
    "\n",
    "            \n",
    "            # Update parameters\n",
    "            trainable_variables = model.trainable_variables\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "            batch_loss /= batch_size\n",
    "            print(\"batch_loss\", batch_loss)\n",
    "        epoch_loss += batch_loss\n",
    "            \n",
    "        print('(epoch {}/{}), train_loss = {:.3f}'.format(\n",
    "                    epoch,\n",
    "                    num_epochs,\n",
    "                    epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
